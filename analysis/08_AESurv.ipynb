{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08-AESurv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9higxKs51Eb2wDXbl/Cjd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunjie-sam-liu/TEP-prognosis/blob/main/analysis/08_AESurv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eHaHjGj_8aw",
        "outputId": "02489dd1-d475-4625-a211-2bf37a3f04c9"
      },
      "source": [
        "! pip install torchtuples"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtuples\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/70/93eb42c0a46ef94b3885b8e5611a8019d00522a9ab7343d4ca25033afd44/torchtuples-0.2.0-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->torchtuples) (1.15.0)\n",
            "Installing collected packages: torchtuples\n",
            "Successfully installed torchtuples-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqR92inbAO_i",
        "outputId": "5d27794b-a4dd-4bd1-f0b4-6ed743e39da4"
      },
      "source": [
        "! pip install pycox"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/8166da2d22ff30305aa0c10e0c6124ef5d3b60b5b0418387bb805bd6b751/pycox-0.2.1-py3-none-any.whl (73kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 51kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 61kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.44 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.48.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.10.0)\n",
            "Requirement already satisfied: torchtuples>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.2.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.22.2.post1)\n",
            "Requirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (1.19.5)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (51.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9.0->pycox) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (1.1.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.0.0)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format>=0.4.0->pycox) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2018.9)\n",
            "Installing collected packages: pycox\n",
            "Successfully installed pycox-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8kS4rko_4zK"
      },
      "source": [
        "import numpy as np\n",
        "import feather\n",
        "\n",
        "# For preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.linear import Linear\n",
        "import torchtuples as tt\n",
        "\n",
        "from pycox.models import LogisticHazard\n",
        "from pycox.models.loss import NLLLogistiHazardLoss\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "import os"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFyXnx_tAID4"
      },
      "source": [
        "# random\n",
        "np.random.seed(1234)\n",
        "_ = torch.manual_seed(1234)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qFqbfHMAVkR"
      },
      "source": [
        "class NetAESurv(nn.Module):\n",
        "    def __init__(self, in_features, encoded_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(in_features, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, encoded_features),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoded_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, in_features),\n",
        "        )\n",
        "\n",
        "        # Full connection\n",
        "        self.survnet = nn.Sequential(\n",
        "            nn.Linear(encoded_features, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        encoded = self.encoder(input)\n",
        "        decoded = self.decoder(encoded)\n",
        "        phi = self.survnet(encoded)\n",
        "        return phi, decoded\n",
        "\n",
        "    def predict(self, input):\n",
        "        encoded = self.encoder(input)\n",
        "        return self.survnet(encoded)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAYpU9O-AZta"
      },
      "source": [
        "class LossAELogHaz(nn.Module):\n",
        "    def __init__(self, alpha):\n",
        "        super().__init__()\n",
        "        assert (alpha >= 0) and (alpha <= 1), \"Need `alpha` in [0, 1].\"\n",
        "        self.alpha = alpha\n",
        "        self.loss_surv = NLLLogistiHazardLoss()\n",
        "        self.loss_ae = nn.MSELoss()\n",
        "\n",
        "    def forward(self, phi, decoded, target_loghaz, target_ae):\n",
        "        idx_durations, events = target_loghaz\n",
        "        loss_surv = self.loss_surv(phi, idx_durations, events)\n",
        "        loss_ae = self.loss_ae(decoded, target_ae)\n",
        "        return self.alpha * loss_surv + (1 - self.alpha) * loss_ae\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSwuwhfpAa-x"
      },
      "source": [
        "def load_data(filepath):\n",
        "    df = feather.read_dataframe(source=filepath)\n",
        "    df_train = df.loc[df.oc == \"OC521\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_val = df.loc[df.oc == \"OC44\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_test1 = df.loc[df.oc == \"OC79\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_test2 = df.loc[df.oc == \"OC172\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    return df_train, df_val, df_test1, df_test2\n",
        "\n",
        "\n",
        "def get_target(df):\n",
        "    return (df[\"duration\"].values, df[\"event\"].values)\n",
        "\n",
        "\n",
        "def transform_features(df_train, df_val, df_test1, df_test2):\n",
        "    columns = df_train.columns\n",
        "    columns = columns[: len(columns) - 2]\n",
        "    standardize = [([col], StandardScaler()) for col in columns]\n",
        "\n",
        "    x_mapper = DataFrameMapper(standardize)\n",
        "\n",
        "    x_train = x_mapper.fit_transform(df_train).astype(\"float32\")\n",
        "    x_val = x_mapper.transform(df_val).astype(\"float32\")\n",
        "    x_test1 = x_mapper.transform(df_test1).astype(\"float32\")\n",
        "    x_test2 = x_mapper.transform(df_test2).astype(\"float32\")\n",
        "\n",
        "    return x_train, x_val, x_test1, x_test2\n",
        "\n",
        "\n",
        "def transform_labels(df_train, df_val, nd=10):\n",
        "    num_durations = nd\n",
        "    labtrans = LogisticHazard.label_transform(num_durations)\n",
        "    y_train_surv = labtrans.fit_transform(*get_target(df_train))\n",
        "    y_val_surv = labtrans.transform(*get_target(df_val))\n",
        "\n",
        "    return y_train_surv, y_val_surv, labtrans\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQROz4CWCBzz",
        "outputId": "71534c76-ee3f-49a3-e21e-650c060c7737"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rme6b6nFApwI"
      },
      "source": [
        "filepath=\"/content/drive/MyDrive/colab-data/total416.os.se.norm.feather\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckeNJX8eAdiO"
      },
      "source": [
        "# load data\n",
        "df_train, df_val, df_test1, df_test2 = load_data(filepath)\n",
        "# transform features\n",
        "x_train, x_val, x_test1, x_test2 = transform_features(df_train, df_val, df_test1, df_test2)\n",
        "# transform labels\n",
        "y_train_surv, y_val_surv, labtrans = transform_labels(df_train, df_val)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS2tDcGuAtXh"
      },
      "source": [
        "# make train and validation datasets with tuplefy\n",
        "train = tt.tuplefy(x_train, (y_train_surv, x_train))\n",
        "val = tt.tuplefy(x_val, (y_val_surv, x_val))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_85i-DMuFQeN"
      },
      "source": [
        "# set arch\n",
        "in_features = x_train.shape[1]\n",
        "encoded_features = 64\n",
        "out_features = labtrans.out_features\n",
        "netaesurv = NetAESurv(in_features, encoded_features, out_features)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lBjpxthFVne",
        "outputId": "74102fd8-66b4-404d-b543-445fcbb1a4ac"
      },
      "source": [
        "netaesurv"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NetAESurv(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=6636, out_features=2048, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=2048, out_features=6636, bias=True)\n",
              "  )\n",
              "  (survnet): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmW0eWTUFW_l"
      },
      "source": [
        "# loss\n",
        "loss = LossAELogHaz(0.6)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GztAp5qfFkqG",
        "outputId": "688f33a8-8fb8-4ddf-ae6d-99a417df8451"
      },
      "source": [
        "loss"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LossAELogHaz(\n",
              "  (loss_surv): NLLLogistiHazardLoss()\n",
              "  (loss_ae): MSELoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKVSa6u-Flut"
      },
      "source": [
        "# model\n",
        "model = LogisticHazard(net=netaesurv, optimizer=tt.optim.Adam(0.01), duration_index=labtrans.cuts, loss=loss)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHTHX5wNFocW"
      },
      "source": [
        "# metrics\n",
        "metrics = dict(loss_surv=LossAELogHaz(1), loss_ae=LossAELogHaz(0))\n",
        "\n",
        "# callbacks\n",
        "callbacks = [tt.cb.EarlyStopping()]\n",
        "\n",
        "# cycling\n",
        "batch_size = 5\n",
        "epochs = 10\n",
        "\n",
        "# trainning model\n",
        "log = model.fit(\n",
        "    *train, batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=False, val_data=val, metrics=metrics\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIIxAInIFtpt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}