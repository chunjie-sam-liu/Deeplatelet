{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-AEPFS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXq0BdKTM3T6eYspaoQNg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunjie-sam-liu/TEP-prognosis/blob/main/analysis/09_AEPFS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmFLv2xG-Cm",
        "outputId": "d196484f-9452-44f1-c790-b7758a2549ca"
      },
      "source": [
        "! pip install torchtuples\n",
        "! pip install pycox\n",
        "! pip install hiddenlayer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtuples\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/70/93eb42c0a46ef94b3885b8e5611a8019d00522a9ab7343d4ca25033afd44/torchtuples-0.2.0-py3-none-any.whl (41kB)\n",
            "\r\u001b[K     |███████▉                        | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 20kB 19.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 30kB 23.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 40kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from torchtuples) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->torchtuples) (1.15.0)\n",
            "Installing collected packages: torchtuples\n",
            "Successfully installed torchtuples-0.2.0\n",
            "Collecting pycox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/8166da2d22ff30305aa0c10e0c6124ef5d3b60b5b0418387bb805bd6b751/pycox-0.2.1-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: feather-format>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.23.0)\n",
            "Requirement already satisfied: numba>=0.44 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.48.0)\n",
            "Requirement already satisfied: torchtuples>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.6/dist-packages (from pycox) (2.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from pycox) (0.22.2.post1)\n",
            "Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format>=0.4.0->pycox) (0.14.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pycox) (1.24.3)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (51.1.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba>=0.44->pycox) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from torchtuples>=0.2.0->pycox) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9.0->pycox) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->pycox) (1.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->torchtuples>=0.2.0->pycox) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->torchtuples>=0.2.0->pycox) (2018.9)\n",
            "Installing collected packages: pycox\n",
            "Successfully installed pycox-0.2.1\n",
            "Collecting hiddenlayer\n",
            "  Downloading https://files.pythonhosted.org/packages/64/f8/ea51d02695a4dc397f3b2487fae462cd3f2ce707c54250e0fdfaec2ff92e/hiddenlayer-0.3-py3-none-any.whl\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v8uaB0mHK__"
      },
      "source": [
        "import numpy as np\n",
        "import feather\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.linear import Linear\n",
        "import torchtuples as tt\n",
        "\n",
        "from pycox.models import LogisticHazard\n",
        "from pycox.models.loss import NLLLogistiHazardLoss\n",
        "from pycox.evaluation import EvalSurv\n",
        "\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPKHuhrLHMRX"
      },
      "source": [
        "# random\n",
        "np.random.seed(1234)\n",
        "_ = torch.manual_seed(1234)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRaWhy3iHNZV"
      },
      "source": [
        "class NetAESurv(nn.Module):\n",
        "    def __init__(self, in_features, encoded_features, out_features):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(in_features, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, encoded_features),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoded_features, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, in_features),\n",
        "        )\n",
        "\n",
        "        # Full connection\n",
        "        self.survnet = nn.Sequential(\n",
        "            nn.Linear(encoded_features, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        encoded = self.encoder(input)\n",
        "        decoded = self.decoder(encoded)\n",
        "        phi = self.survnet(encoded)\n",
        "        return phi, decoded\n",
        "\n",
        "    def predict(self, input):\n",
        "        encoded = self.encoder(input)\n",
        "        return self.survnet(encoded)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWqlSItqHSZ9"
      },
      "source": [
        "class LossAELogHaz(nn.Module):\n",
        "    def __init__(self, alpha):\n",
        "        super().__init__()\n",
        "        assert (alpha >= 0) and (alpha <= 1), \"Need `alpha` in [0, 1].\"\n",
        "        self.alpha = alpha\n",
        "        self.loss_surv = NLLLogistiHazardLoss()\n",
        "        self.loss_ae = nn.MSELoss()\n",
        "\n",
        "    def forward(self, phi, decoded, target_loghaz, target_ae):\n",
        "        idx_durations, events = target_loghaz\n",
        "        loss_surv = self.loss_surv(phi, idx_durations, events)\n",
        "        loss_ae = self.loss_ae(decoded, target_ae)\n",
        "        return self.alpha * loss_surv + (1 - self.alpha) * loss_ae\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtvMCMTXHUX9"
      },
      "source": [
        "def load_data(filepath):\n",
        "    df = feather.read_dataframe(source=filepath)\n",
        "    df_train = df.loc[df.oc == \"OC521\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_val = df.loc[df.oc == \"OC44\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_test1 = df.loc[df.oc == \"OC79\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    df_test2 = df.loc[df.oc == \"OC172\"].drop(columns=[\"barcode\", \"oc\"], axis=1)\n",
        "    return df_train, df_val, df_test1, df_test2\n",
        "\n",
        "\n",
        "def get_target(df):\n",
        "    return (df[\"duration\"].values, df[\"event\"].values)\n",
        "\n",
        "\n",
        "def transform_features(df_train, df_val, df_test1, df_test2):\n",
        "    columns = df_train.columns\n",
        "    columns = columns[: len(columns) - 2]\n",
        "    standardize = [([col], StandardScaler()) for col in columns]\n",
        "\n",
        "    x_mapper = DataFrameMapper(standardize)\n",
        "\n",
        "    x_train = x_mapper.fit_transform(df_train).astype(\"float32\")\n",
        "    x_val = x_mapper.transform(df_val).astype(\"float32\")\n",
        "    x_test1 = x_mapper.transform(df_test1).astype(\"float32\")\n",
        "    x_test2 = x_mapper.transform(df_test2).astype(\"float32\")\n",
        "\n",
        "    return x_train, x_val, x_test1, x_test2\n",
        "\n",
        "\n",
        "def transform_labels(df_train, df_val, nd=10):\n",
        "    num_durations = nd\n",
        "    labtrans = LogisticHazard.label_transform(num_durations)\n",
        "    y_train_surv = labtrans.fit_transform(*get_target(df_train))\n",
        "    y_val_surv = labtrans.transform(*get_target(df_val))\n",
        "\n",
        "    return y_train_surv, y_val_surv, labtrans\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdvN7GqHVcl",
        "outputId": "57d8823c-5355-4c95-89e6-4e5849e28e6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiPes9NzHa2W"
      },
      "source": [
        "filepath=\"/content/drive/MyDrive/colab-data/total434.pfs.se.norm.feather\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG-Pg1oaHuSm"
      },
      "source": [
        "# load data\n",
        "df_train, df_val, df_test1, df_test2 = load_data(filepath)\n",
        "# transform features\n",
        "x_train, x_val, x_test1, x_test2 = transform_features(df_train, df_val, df_test1, df_test2)\n",
        "# transform labels\n",
        "y_train_surv, y_val_surv, labtrans = transform_labels(df_train, df_val)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uWaBNc3Hvym"
      },
      "source": [
        "# make train and validation datasets with tuplefy\n",
        "train = tt.tuplefy(x_train, (y_train_surv, x_train))\n",
        "val = tt.tuplefy(x_val, (y_val_surv, x_val))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqxTY918HyZ2"
      },
      "source": [
        "durations_test1, events_test1 = get_target(df_test1)\n",
        "durations_test2, events_test2 = get_target(df_test2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM7kgvfiH0nm"
      },
      "source": [
        "# set arch\n",
        "in_features = x_train.shape[1]\n",
        "encoded_features = 64\n",
        "out_features = labtrans.out_features\n",
        "netaesurv = NetAESurv(in_features, encoded_features, out_features)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W62937pLH1Te",
        "outputId": "f973f667-c8a1-41cd-dc2d-d3edb927675a"
      },
      "source": [
        "netaesurv"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NetAESurv(\n",
              "  (encoder): Sequential(\n",
              "    (0): Linear(in_features=6670, out_features=2048, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=1024, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=1024, out_features=2048, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): Linear(in_features=2048, out_features=6670, bias=True)\n",
              "  )\n",
              "  (survnet): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w1XfjgNH2rq",
        "outputId": "d7e58698-65ba-4f46-a8c9-74cbe4fa715b"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model=netaesurv, input_size=(1, in_features))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1              [-1, 1, 2048]      13,662,208\n",
            "              ReLU-2              [-1, 1, 2048]               0\n",
            "            Linear-3              [-1, 1, 1024]       2,098,176\n",
            "              ReLU-4              [-1, 1, 1024]               0\n",
            "            Linear-5               [-1, 1, 512]         524,800\n",
            "              ReLU-6               [-1, 1, 512]               0\n",
            "            Linear-7               [-1, 1, 256]         131,328\n",
            "              ReLU-8               [-1, 1, 256]               0\n",
            "            Linear-9               [-1, 1, 128]          32,896\n",
            "             ReLU-10               [-1, 1, 128]               0\n",
            "           Linear-11                [-1, 1, 64]           8,256\n",
            "           Linear-12               [-1, 1, 128]           8,320\n",
            "             ReLU-13               [-1, 1, 128]               0\n",
            "           Linear-14               [-1, 1, 256]          33,024\n",
            "             ReLU-15               [-1, 1, 256]               0\n",
            "           Linear-16               [-1, 1, 512]         131,584\n",
            "             ReLU-17               [-1, 1, 512]               0\n",
            "           Linear-18              [-1, 1, 1024]         525,312\n",
            "             ReLU-19              [-1, 1, 1024]               0\n",
            "           Linear-20              [-1, 1, 2048]       2,099,200\n",
            "             ReLU-21              [-1, 1, 2048]               0\n",
            "           Linear-22              [-1, 1, 6670]      13,666,830\n",
            "           Linear-23                [-1, 1, 64]           4,160\n",
            "             ReLU-24                [-1, 1, 64]               0\n",
            "           Linear-25                [-1, 1, 64]           4,160\n",
            "             ReLU-26                [-1, 1, 64]               0\n",
            "           Linear-27                [-1, 1, 64]           4,160\n",
            "             ReLU-28                [-1, 1, 64]               0\n",
            "           Linear-29                [-1, 1, 10]             650\n",
            "================================================================\n",
            "Total params: 32,935,064\n",
            "Trainable params: 32,935,064\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 0.18\n",
            "Params size (MB): 125.64\n",
            "Estimated Total Size (MB): 125.84\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "_9L2maikH3-0",
        "outputId": "f2b21869-f607-47b6-d838-6d4337a47e7f"
      },
      "source": [
        "import hiddenlayer as hl\n",
        "hl.build_graph(netaesurv, torch.zeros([1, in_features]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hiddenlayer.graph.Graph at 0x7fbdd5b75cf8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"504pt\" height=\"178pt\"\n viewBox=\"0.00 0.00 504.00 178.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 142)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-142 432,-142 432,36 -72,36\"/>\n<!-- /outputs/43 -->\n<g id=\"node1\" class=\"node\">\n<title>/outputs/43</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"162,-71 108,-71 108,-35 162,-35 162,-71\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-50\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- 7562392448782495911 -->\n<g id=\"node4\" class=\"node\">\n<title>7562392448782495911</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"270,-106 198,-106 198,-62 270,-62 270,-106\"/>\n<text text-anchor=\"start\" x=\"206\" y=\"-90\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n<text text-anchor=\"start\" x=\"255\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x3</text>\n</g>\n<!-- /outputs/43&#45;&gt;7562392448782495911 -->\n<g id=\"edge1\" class=\"edge\">\n<title>/outputs/43&#45;&gt;7562392448782495911</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M162.0522,-61.4709C170.1245,-63.9986 179.2072,-66.8427 188.1316,-69.6372\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"187.1092,-72.9845 197.6982,-72.6328 189.201,-66.3044 187.1092,-72.9845\"/>\n</g>\n<!-- 1526261397950410261 -->\n<g id=\"node6\" class=\"node\">\n<title>1526261397950410261</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"270,-44 198,-44 198,0 270,0 270,-44\"/>\n<text text-anchor=\"start\" x=\"206\" y=\"-28\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n<text text-anchor=\"start\" x=\"255\" y=\"-7\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x5</text>\n</g>\n<!-- /outputs/43&#45;&gt;1526261397950410261 -->\n<g id=\"edge4\" class=\"edge\">\n<title>/outputs/43&#45;&gt;1526261397950410261</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M162.0522,-44.5291C170.1245,-42.0014 179.2072,-39.1573 188.1316,-36.3628\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"189.201,-39.6956 197.6982,-33.3672 187.1092,-33.0155 189.201,-39.6956\"/>\n</g>\n<!-- /outputs/54 -->\n<g id=\"node2\" class=\"node\">\n<title>/outputs/54</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"360,-40 306,-40 306,-4 360,-4 360,-40\"/>\n<text text-anchor=\"start\" x=\"320\" y=\"-19\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- /outputs/61 -->\n<g id=\"node3\" class=\"node\">\n<title>/outputs/61</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"360,-102 306,-102 306,-66 360,-66 360,-102\"/>\n<text text-anchor=\"start\" x=\"320\" y=\"-81\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n</g>\n<!-- 7562392448782495911&#45;&gt;/outputs/61 -->\n<g id=\"edge2\" class=\"edge\">\n<title>7562392448782495911&#45;&gt;/outputs/61</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M270.0213,-84C278.3402,-84 287.2088,-84 295.5856,-84\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.8548,-87.5001 305.8547,-84 295.8547,-80.5001 295.8548,-87.5001\"/>\n</g>\n<!-- 7447486864029635386 -->\n<g id=\"node5\" class=\"node\">\n<title>7447486864029635386</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"72,-75 0,-75 0,-31 72,-31 72,-75\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-59\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n<text text-anchor=\"start\" x=\"57\" y=\"-38\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x5</text>\n</g>\n<!-- 7447486864029635386&#45;&gt;/outputs/43 -->\n<g id=\"edge3\" class=\"edge\">\n<title>7447486864029635386&#45;&gt;/outputs/43</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72.0213,-53C80.3402,-53 89.2088,-53 97.5856,-53\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"97.8548,-56.5001 107.8547,-53 97.8547,-49.5001 97.8548,-56.5001\"/>\n</g>\n<!-- 1526261397950410261&#45;&gt;/outputs/54 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1526261397950410261&#45;&gt;/outputs/54</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M270.0213,-22C278.3402,-22 287.2088,-22 295.5856,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.8548,-25.5001 305.8547,-22 295.8547,-18.5001 295.8548,-25.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb_vPXKcH5jV"
      },
      "source": [
        "# loss\n",
        "loss = LossAELogHaz(0.6)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5WP9GsdH7VV",
        "outputId": "fb470d24-09a2-45de-c627-f749437b6ac7"
      },
      "source": [
        "loss"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LossAELogHaz(\n",
              "  (loss_surv): NLLLogistiHazardLoss()\n",
              "  (loss_ae): MSELoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znvancG6H8hC"
      },
      "source": [
        "# model\n",
        "model = LogisticHazard(net=netaesurv, optimizer=tt.optim.Adam(0.01), duration_index=labtrans.cuts, loss=loss)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yAxE8rHH9lW",
        "outputId": "95b0414a-19ef-4f93-ef3d-19fb9850bf87"
      },
      "source": [
        "# metrics\n",
        "metrics = dict(loss_surv=LossAELogHaz(1), loss_ae=LossAELogHaz(0))\n",
        "\n",
        "# callbacks\n",
        "callbacks = [tt.cb.EarlyStopping()]\n",
        "\n",
        "# cycling\n",
        "batch_size = 5\n",
        "epochs = 100\n",
        "\n",
        "# trainning model\n",
        "log = model.fit(\n",
        "    *train, batch_size=batch_size, epochs=epochs,  verbose=True, val_data=val, metrics=metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\t[18s / 18s],\t\ttrain_loss: 173.7112,\ttrain_loss_surv: 1.4559,\ttrain_loss_ae: 432.0942,\tval_loss: 1.2279,\tval_loss_surv: 1.4820,\tval_loss_ae: 0.8469\n",
            "1:\t[18s / 37s],\t\ttrain_loss: 1.1113,\ttrain_loss_surv: 1.1827,\ttrain_loss_ae: 1.0043,\tval_loss: 1.1995,\tval_loss_surv: 1.4402,\tval_loss_ae: 0.8386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW8HAbmiH_P2"
      },
      "source": [
        "res = model.log.to_pandas()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}